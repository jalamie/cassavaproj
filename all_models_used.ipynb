{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import pathlib\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='./resized_data_split/train'\n",
    "test_path='./resized_data_split/test'\n",
    "\n",
    "#set the batch size for CNN\n",
    "train_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "train_loader_100=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=100, shuffle=True\n",
    ")\n",
    "test_loader_100=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=100, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=5):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "        #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=5).to(device)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "\n",
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model for no weights, no drop prob and size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model for no weights no drop prob size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_dropout(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_prob=0.5):\n",
    "        super(ConvNet_dropout, self).__init__()\n",
    "        \n",
    "        # Output size after convolution filter ((w-f+2P)/s) + 1\n",
    "        \n",
    "        # Input shape = (256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # Reduce the image size by factor 2\n",
    "        # Shape = (256, 12, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 20, 75, 75)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Shape = (256, 20, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout3 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=75 * 75 * 32, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "            \n",
    "        output = self.pool(output)\n",
    "        output = self.dropout1(output)\n",
    "            \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.dropout2(output)\n",
    "            \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.dropout3(output)\n",
    "            \n",
    "        # Above output will be in matrix form, with shape (256, 32, 75, 75)\n",
    "        output = output.view(-1, 32 * 75 * 75)\n",
    "            \n",
    "        output = self.fc(output)\n",
    "            \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = ConvNet_dropout(num_classes=5, dropout_prob=0.1).to(device)\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 no weight batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 no weight batch size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = ConvNet_dropout(num_classes=5, dropout_prob=0.2).to(device)\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.2 no weight batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.2 no weight batch size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = ConvNet_dropout(num_classes=5, dropout_prob=0.1).to(device)\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all labels\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for _, labels in train_loader_32:\n",
    "    # Append labels to the list\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "# Convert the list to a tensor\n",
    "all_labels_tensor = torch.tensor(all_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = 1.0 / torch.sqrt(torch.bincount(all_labels_tensor).float() / len(all_labels_tensor))\n",
    "\n",
    "# Convert class weights to a PyTorch tensor\n",
    "class_weights = torch.FloatTensor(class_weights)\n",
    "\n",
    "# Use the calculated class weights in the CrossEntropyLoss\n",
    "loss_function_weighted = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 with class weight batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function_weighted(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 with class weight batch size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all labels\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for _, labels in train_loader_100:\n",
    "    # Append labels to the list\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "# Convert the list to a tensor\n",
    "all_labels_tensor = torch.tensor(all_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = 1.0 / torch.sqrt(torch.bincount(all_labels_tensor).float() / len(all_labels_tensor))\n",
    "\n",
    "# Convert class weights to a PyTorch tensor\n",
    "class_weights = torch.FloatTensor(class_weights)\n",
    "\n",
    "# Use the calculated class weights in the CrossEntropyLoss\n",
    "loss_function_weighted = nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function_weighted(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 with class weight batch size 100 learning rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.01,weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_dropout_tanh(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_prob=0.5):\n",
    "        super(ConvNet_dropout_tanh, self).__init__()\n",
    "        \n",
    "        # Output size after convolution filter ((w-f+2P)/s) + 1\n",
    "        \n",
    "        # Input shape = (256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # Reduce the image size by factor 2\n",
    "        # Shape = (256, 12, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 20, 75, 75)\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        # Shape = (256, 20, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout3 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=75 * 75 * 32, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.tanh1(output)\n",
    "            \n",
    "        output = self.pool(output)\n",
    "        output = self.dropout1(output)\n",
    "            \n",
    "        output = self.conv2(output)\n",
    "        output = self.tanh2(output)\n",
    "        output = self.dropout2(output)\n",
    "            \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.tanh3(output)\n",
    "        output = self.dropout3(output)\n",
    "            \n",
    "        # Above output will be in matrix form, with shape (256, 32, 75, 75)\n",
    "        output = output.view(-1, 32 * 75 * 75)\n",
    "            \n",
    "        output = self.fc(output)\n",
    "            \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout_tanh = ConvNet_dropout_tanh(num_classes=5, dropout_prob=0.1).to(device)\n",
    "optimizer_dropout_tanh=Adam(model_dropout_tanh.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 no class weight batch size 100 learning rate = 0.001 tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_tanh.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_tanh.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_tanh(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_tanh.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_tanh.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_tanh(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_tanh.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 no class weight batch size 32 learning rate = 0.001 tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_tanh.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_tanh.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_tanh(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_tanh.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_tanh.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_tanh(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_tanh.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_dropout_avgpool(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_prob=0.5):\n",
    "        super(ConvNet_dropout_avgpool, self).__init__()\n",
    "        \n",
    "        # Output size after convolution filter ((w-f+2P)/s) + 1\n",
    "        \n",
    "        # Input shape = (256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Shape = (256, 12, 150, 150)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2)\n",
    "        # Reduce the image size by factor 2\n",
    "        # Shape = (256, 12, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 20, 75, 75)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Shape = (256, 20, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # Shape = (256, 32, 75, 75)\n",
    "        \n",
    "        # Dropout layer with specified dropout probability\n",
    "        self.dropout3 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=75 * 75 * 32, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "            \n",
    "        output = self.pool(output)\n",
    "        output = self.dropout1(output)\n",
    "            \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.dropout2(output)\n",
    "            \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.dropout3(output)\n",
    "            \n",
    "        # Above output will be in matrix form, with shape (256, 32, 75, 75)\n",
    "        output = output.view(-1, 32 * 75 * 75)\n",
    "            \n",
    "        output = self.fc(output)\n",
    "            \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout_avgpool = ConvNet_dropout_avgpool(num_classes=5, dropout_prob=0.1).to(device)\n",
    "optimizer_dropout_avgpool=Adam(model_dropout_avgpool.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 with class weight batch size 32 learning rate = 0.001 avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_avgpool.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_avgpool.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function_weighted(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_avgpool.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_avgpool.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_avgpool.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 with class weight batch size 100 learning rate = 0.001 avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_avgpool.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_avgpool.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function_weighted(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_avgpool.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_avgpool.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_avgpool.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 no class weight batch size 32 learning rate = 0.001 avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_avgpool.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_avgpool.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_avgpool.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_avgpool.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_avgpool.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.1 no class weight batch size 100 learning rate = 0.001 avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_avgpool.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_avgpool.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function_weighted(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_avgpool.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_avgpool.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_avgpool.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout_avgpool = ConvNet_dropout_avgpool(num_classes=5, dropout_prob=0.2).to(device)\n",
    "optimizer_dropout_avgpool=Adam(model_dropout_avgpool.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for dropout prob = 0.2 no class weight batch size 100 learning rate = 0.001 avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout_avgpool.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout_avgpool.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout_avgpool.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout_avgpool.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout_avgpool(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout_avgpool.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_complex(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_prob=0.3):\n",
    "        super(ConvNet_complex, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout3 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=128 * 18 * 18, out_features=512)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout_fc1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.dropout1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "        output = self.dropout2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.pool3(output)\n",
    "        output = self.dropout3(output)\n",
    "        \n",
    "        output = output.view(-1, 128 * 18 * 18)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.relu_fc1(output)\n",
    "        output = self.dropout_fc1(output)\n",
    "        \n",
    "        output = self.fc2(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complex = ConvNet_complex(num_classes=5, dropout_prob=0.1).to(device)\n",
    "optimizer_complex=Adam(model_complex.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complex ReLu max pooling batch size 100, no class weights learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_complex.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_complex.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_complex(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_complex.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_complex.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_100):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_complex(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_complex.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='./gray_data/train'\n",
    "test_path='./gray_data/test'\n",
    "\n",
    "#set the batch size for CNN\n",
    "train_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = ConvNet_dropout(num_classes=5, dropout_prob=0.2).to(device)\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='./sharpened_data/train'\n",
    "test_path='./sharpened_data/test'\n",
    "\n",
    "#set the batch size for CNN\n",
    "train_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = ConvNet_dropout(num_classes=5, dropout_prob=0.2).to(device)\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(5):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='./resized_data_split_less/train'\n",
    "test_path='./resized_data_split_less/test'\n",
    "\n",
    "#set the batch size for CNN\n",
    "train_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader_32=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = ConvNet_dropout(num_classes=4, dropout_prob=0.2).to(device)\n",
    "optimizer_dropout=Adam(model_dropout.parameters(),lr=0.001,weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and saving the best model\n",
    "\n",
    "# Initialize the best accuracy variable\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model_dropout.train()\n",
    "    \n",
    "    # Initialize training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Iterate through the training dataset\n",
    "    for i, (images, labels) in enumerate(train_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Zero the gradients\n",
    "        optimizer_dropout.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer_dropout.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    # Calculate average training accuracy and loss\n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss / train_count\n",
    "    # Initialize the confusion matrix\n",
    "    conf_matrix = torch.zeros(5, 5)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model_dropout.eval()\n",
    "    \n",
    "    # Initialize testing accuracy\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    # Iterate through the testing dataset\n",
    "    for i, (images, labels) in enumerate(test_loader_32):\n",
    "        # Move images and labels to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model_dropout(images)\n",
    "        \n",
    "        # Calculate testing accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), prediction.cpu().numpy(), labels=list(range(5)))\n",
    "    \n",
    "    # Calculate average testing accuracy\n",
    "    test_accuracy = test_accuracy / test_count\n",
    "    class_accuracy = conf_matrix.diag() / conf_matrix.sum(1)\n",
    "\n",
    "    # Print class-wise accuracy\n",
    "    for i in range(4):\n",
    "        print(f'Class {i} Accuracy: {class_accuracy[i].item()}')\n",
    "        # scheduler.step()\n",
    "        # Print epoch-wise results\n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) +\n",
    "        ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n",
    "    \n",
    "    # Save the best model based on testing accuracy\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_dropout.state_dict(), 'best_checkpoint_dropout.model')\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3 (v3.11.3:f3909b8bc8, Apr  4 2023, 20:12:10) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
